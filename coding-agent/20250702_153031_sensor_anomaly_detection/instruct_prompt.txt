**Prompt for Instruct LLM: Generate Machine Learning Pipeline**

**Task: Sensor Anomaly Detection Pipeline**

Write a Python script named `run_pipeline.py` that implements a machine learning pipeline for sensor anomaly detection. The script should load time-series sensor data from `sensor_data.csv`, preprocess it by handling missing values, create time-windowed features, and generate anomaly labels based on a defined heuristic. It will then train a Random Forest Classifier to predict anomalies within these windows and evaluate its performance.

**Dataset Information:**
*   **File Name:** `sensor_data.csv`
*   **Columns:** `sensor_1`, `sensor_2`, `sensor_3`
*   **Data Type:** Numerical (float)
*   **Rows:** 1440
*   **Characteristics:** Time-series data (implicitly ordered by row index), contains missing values (NaN).

**Pipeline Steps:**

1.  **Data Loading and Initial Check:**
    *   Load `sensor_data.csv` using pandas.
    *   If the file does not exist, print an error message "Error: sensor_data.csv not found." to standard output and exit the script gracefully. Do NOT generate any dummy or random data. Focus solely on the provided real data.

2.  **Preprocessing:**
    *   **Missing Value Imputation:** Impute `NaN` values in `sensor_1`, `sensor_2`, and `sensor_3` columns using the *mean* of each respective column.
    *   **Anomaly Label Generation (Crucial Simulation for Classification Task):**
        *   This dataset does not inherently contain an anomaly label. For the purpose of training a classifier, create a binary target variable `is_anomaly` (0 for normal, 1 for anomaly) for each window.
        *   Calculate the global mean and standard deviation for each sensor (`sensor_1`, `sensor_2`, `sensor_3`) across the *entire dataset* after imputation.
        *   Define an anomaly threshold for each sensor: `mean + 3 * std` and `mean - 3 * std`. These thresholds will be applied to individual data points within a window.
    *   **Windowing and Feature Extraction:**
        *   Define `window_size = 10` and `overlap = 5`.
        *   Iterate through the preprocessed sensor data, creating overlapping windows.
        *   For each window:
            *   Extract descriptive statistics as features (X): `mean`, `standard deviation`, `min`, `max` for each of `sensor_1`, `sensor_2`, `sensor_3`. This will result in 12 features per window.
            *   Determine the window's anomaly label (y): If *any* individual sensor reading within that window (for `sensor_1`, `sensor_2`, or `sensor_3`) falls outside its pre-defined global anomaly thresholds (i.e., `value > mean + 3*std` or `value < mean - 3*std`), label the entire window as `1` (anomalous). Otherwise, label it as `0` (normal).
    *   **Feature Scaling:** Apply `sklearn.preprocessing.StandardScaler` to the extracted window features (`X`).

3.  **Model Configuration:**
    *   Use `sklearn.ensemble.RandomForestClassifier`.
    *   Set hyperparameters: `n_estimators=100`, `random_state=42`.

4.  **Training Process:**
    *   Split the processed data (X, y) into training, validation, and test sets.
    *   Use a split ratio of `80%` for training, `10%` for validation, and `10%` for testing.
    *   Ensure the data splits are deterministic and reproducible by setting `random_state=42` in `train_test_split` calls.
    *   Train the `RandomForestClassifier` on the training data.

5.  **Evaluation:**
    *   Make predictions on the test set.
    *   Compute the following classification metrics on the test set:
        *   `Accuracy Score`
        *   `Precision Score` (for the positive class, i.e., anomaly = 1)
        *   `Recall Score` (for the positive class, i.e., anomaly = 1)
        *   `F1-Score` (for the positive class, i.e., anomaly = 1)
    *   The primary evaluation metrics for saving results should be from the test set.

6.  **Save Results:**
    *   Create a directory named `result` if it does not already exist using `os.makedirs`.
    *   Save a JSON file named `results.json` inside the `result` directory.
    *   The `results.json` file should contain:
        *   All computed evaluation metrics (accuracy, precision, recall, F1-score).
        *   The hyperparameters used for the `RandomForestClassifier` (`n_estimators`, `random_state`).

**Constraints and Best Practices:**
*   Do NOT create any synthetic, random, or dummy data. Work strictly with the actual `sensor_data.csv` file.
*   Ensure all data splits and model training are reproducible by setting `random_state` parameters where applicable.
*   Use standard, commonly available Python libraries (e.g., pandas, numpy, scikit-learn, os, json). Avoid rarely used libraries that might require complex installations.
*   The script should be modular and clear.
*   Do not include notes or comments in the generated source code.
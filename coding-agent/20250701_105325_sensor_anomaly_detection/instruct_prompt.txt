Generate a Python script named `run_pipeline.py` that implements a machine learning pipeline for sensor anomaly detection using window-based classification.

**Task Overview:**
The goal is to train a classifier to detect anomalies in time-series sensor data. The dataset, `sensor_data.csv`, contains sensor readings over time without explicit anomaly labels. The pipeline should first synthetically introduce anomalies to create a supervised dataset, then transform the time series into overlapping windows, and finally train and evaluate a classifier on these windows.

**Data Loading:**
1.  Load the dataset `sensor_data.csv` into a pandas DataFrame. The dataset has three sensor columns: `sensor_1`, `sensor_2`, `sensor_3`.

**Preprocessing Steps & Feature Engineering:**
1.  **Synthetic Anomaly Generation:**
    *   Add a new column `is_anomaly` to the DataFrame, initialized to 0 (normal).
    *   Randomly select approximately 5-10% of the data points and mark them as anomalies (set `is_anomaly` to 1).
    *   For these selected anomalous points, significantly perturb their sensor values (e.g., add or subtract a large random value, or a multiple of the standard deviation of each sensor column) to simulate anomalous readings. Ensure the perturbations are distinct enough to be potential outliers.
2.  **Window Creation:**
    *   Define a `window_size` (e.g., 60 data points) and an `overlap` (e.g., 30 data points).
    *   Iterate through the DataFrame to create overlapping windows. Each window will be a new sample for the classifier.
    *   For each window:
        *   Extract the sensor readings for `sensor_1`, `sensor_2`, `sensor_3`.
        *   Flatten these sensor readings into a single feature vector (e.g., a window of 60 data points across 3 sensors will result in a feature vector of length 180).
        *   Determine the label for the window: If *any* data point within that window has `is_anomaly=1`, the entire window's label should be 1 (anomalous); otherwise, 0 (normal).
    *   Store these window features and labels in a new DataFrame or NumPy arrays.
3.  **Data Scaling:**
    *   Apply `StandardScaler` from `sklearn.preprocessing` to the created window features.

**Data Splitting:**
1.  Split the windowed dataset into training, validation, and test sets using an 80%, 10%, 10% split respectively.
2.  Crucially, ensure a **chronological split** to maintain temporal order. Do not shuffle the data before splitting. This means taking the first 80% for training, the next 10% for validation, and the final 10% for testing.

**Model Configuration & Training Process:**
1.  **Model Selection:** Use `RandomForestClassifier` from `sklearn.ensemble`.
2.  **Hyperparameters:**
    *   `n_estimators=100`
    *   `random_state=42`
    *   You may include other common parameters if deemed necessary for robustness.
3.  **Training:** Train the `RandomForestClassifier` model using the training set.

**Evaluation:**
1.  Evaluate the trained model on the test set.
2.  Compute and report the following evaluation metrics using `sklearn.metrics`:
    *   Accuracy
    *   Precision
    *   Recall
    *   F1-score

**Save Results:**
1.  Create a directory named `result` if it does not already exist.
2.  Save the following information into a JSON file named `results.json` inside the `result` directory:
    *   All computed evaluation metrics (accuracy, precision, recall, F1-score) on the test set.
    *   The hyperparameters used for the `RandomForestClassifier` model (e.g., `n_estimators`, `random_state`).

**Additional Requirements:**
*   The script should be self-contained and run directly.
*   Avoid using external libraries that are not commonly available (e.g., stick to `pandas`, `numpy`, `sklearn`).
*   Do not include notes or comments in the generated source code.
*   Ensure the script is modular and adaptable.
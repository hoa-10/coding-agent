{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7614ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "# Gán API key (nên lấy từ biến môi trường)\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))  # Đặt API key vào biến môi trường GEMINI_API_KEY\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d536bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt.analyze_data import analyze_dataset_prompt\n",
    "from prompt.trainning_prompt import coding_instruct_prompt\n",
    "#prompt_text = analyze_dataset_prompt(\"sensor_data.csv\")\n",
    "#print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d9a3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Instructions for Implementation LLM: Generate Machine Learning Pipeline Prompt**\n",
      "\n",
      "Your task is to analyze the dataset information located at `{'task': 'Train a classifier to predict whether a sensor reading window indicates an anomaly', 'goal': 'Optimize validation accuracy', 'initial_constraints': 'Use scikit-learn, or lSTM deep learning; preprocess data using time-windowing to capture temporal patterns'}` (which may be in CSV, JSON, or text format describing structure, features, task type, or statistics) and the research idea: '{'dataset_info': {'size': '1440 rows x 3 columns', 'type': 'multivariate time-series', 'data_types': ['float64', 'float64', 'float64']}, 'missing_values': {'sensor_1': '0.97%', 'sensor_2': '0.97%', 'sensor_3': '0.97%', 'handling_method': 'linear interpolation', 'reason': 'Linear interpolation is chosen as it is generally superior for time-series data. It estimates missing values based on neighboring points, thus preserving the temporal continuity and trends inherent in sensor readings. This is crucial for maintaining the integrity of sequential data. Mean or median imputation, while simple, ignores temporal relationships and can introduce artificial flat segments or reduce variance, which is undesirable for time-series analysis and forecasting where the sequence and patterns are vital.'}, 'distribution': {'sensor_1': {'mean': 25.022516952668965, 'std': 7.067018673949446, 'min': 13.596933250579124, 'max': 36.06316898261613}, 'sensor_2': {'mean': 102.51875871436407, 'std': 2.0664506774380333, 'min': 97.82048135475868, 'max': 107.40018455423376}, 'sensor_3': {'mean': 59.96217539452159, 'std': 3.649102307502396, 'min': 52.79757406113937, 'max': 68.91551744385924}, 'notes': 'All sensors exhibit continuous numeric values. Sensor 1 (temperature-like) shows values mostly between 15-35, with a mean around 25, indicative of a typical daily temperature range. Sensor 2 (pressure-like) has a higher mean around 102-105 and a larger range, suggesting it captures more absolute variation. Sensor 3 (humidity-like) varies between 50-65, reflecting a daily humidity cycle. The standard deviations indicate the spread and variability of each sensor. No extreme outliers are apparent from the min/max values; distributions appear somewhat bell-shaped, likely influenced by the cyclical patterns.'}, 'correlation': {'matrix': [[1.0, 0.8199577077608203, 0.007950839655276333], [0.8199577077608203, 1.0, 0.013705505026781636], [0.007950839655276333, 0.013705505026781636, 1.0]], 'notes': 'Strong positive correlation (Pearson R=0.82) between Sensor 1 and Sensor 2.\\nWeak positive correlation (Pearson R=0.01) between Sensor 1 and Sensor 3.\\nWeak positive correlation (Pearson R=0.01) between Sensor 2 and Sensor 3.\\nImplications for tasks: High correlation between sensors can indicate redundancy. For example, if Sensor 1 and 2 are highly correlated, one might be sufficient for certain tasks, or their relationship can be used for anomaly detection (e.g., if one deviates while the other does not). It could also suggest an opportunity for dimensionality reduction (e.g., PCA). Low correlation suggests sensors capture independent aspects of the environment, providing a more comprehensive view when combined for tasks like anomaly detection or comprehensive system state monitoring. For forecasting, correlated sensors can serve as useful exogenous variables for each other.'}, 'trend_seasonality': {'trend': 'present (slight upward trend visible in Sensor 2, Sensor 1 and 3 are more cyclical)', 'seasonality': 'present (visually observed daily cycles for Sensor 1 and 3)', 'notes': 'Formal STL decomposition for a 24-hour (1440-minute) period could not be robustly performed due to the dataset only containing one full day of data. However, visual inspection of the time-series plots strongly suggests a daily (24-hour) cyclical pattern for Sensor 1 and Sensor 3, indicative of typical environmental changes (e.g., temperature/humidity cycles). Sensor 2 shows a slight upward trend over the day with some daily variations but less distinct seasonality.'}, 'preprocessing_recommendations': {'missing_values': 'linear interpolation (with fallback to mean/median for edge cases)', 'normalization': 'StandardScaler', 'time_windowing': '5-10 minute rolling windows (e.g., computing mean, std, min, max within each window)', 'reasons': \"**Missing Values Handling (Method: linear interpolation (with fallback to mean/median for edge cases))**:\\nLinear interpolation is highly recommended for time-series data because it preserves the temporal sequence and trends, estimating missing values based on their temporal neighbors. This is crucial for maintaining the integrity of patterns for tasks like forecasting or anomaly detection. In contrast, simple mean or median imputation can flatten data variance and distort temporal relationships, making it less suitable for time-series analysis.\\n\\n**Normalization (Method: StandardScaler)**:\\nStandardScaler is recommended as a versatile normalization method for sensor data. By transforming data to a mean of 0 and standard deviation of 1, it helps various machine learning algorithms (e.g., SVMs, neural networks, linear models) perform better, as they typically converge faster and are less biased when features are on a similar scale. It also helps preserve the relative magnitude of outliers, which can be critical for anomaly detection in sensor data. While MinMaxScaler is an alternative, StandardScaler often provides a more robust initial transformation for a wider array of tasks.\\n\\n**Time-Windowing (Method: 5-10 minute rolling windows (e.g., computing mean, std, min, max within each window))**:\\nTime-windowing is a vital preprocessing step for time-series sensor data. Aggregating data over short, fixed periods (e.g., 5-10 minutes) helps capture temporal patterns and dependencies that individual data points might miss. It effectively reduces noise, smooths rapid fluctuations, and generates new, informative features (e.g., the average value in the last 10 minutes, the standard deviation of readings, or the rate of change). These aggregated features are invaluable for tasks such as forecasting (predicting the next window's state), classification (identifying events based on a sequence of sensor states), and anomaly detection (recognizing unusual patterns over a short temporal context).\\n\\n**General Suitability for Tasks**:\\nThese preprocessing steps enhance the suitability of sensor data for diverse machine learning tasks. For **classification**, clean, normalized, and contextually rich windowed features enable models to learn distinct patterns associated with different operational states (e.g., normal vs. fault conditions). For **forecasting**, well-handled missing data, consistent scaling, and the creation of lagged or aggregated features provide the necessary temporal context and numerical stability for models to accurately predict future sensor readings. For **anomaly detection**, normalized data simplifies thresholding or model training for deviations from expected behavior, while time-windowing allows for the identification of anomalous *patterns* (e.g., unusual rate of change or sustained high variability) rather than just isolated point anomalies.\"}}'. Based on this analysis, generate a detailed, clear, and concise prompt that instructs another LLM (the instruct LLM) to write a high-quality Python script \n",
      "\n",
      "### Steps to Follow:\n",
      "\n",
      "1. **Analyze Dataset Information**:\n",
      "   - Read and interpret the dataset details from `{'task': 'Train a classifier to predict whether a sensor reading window indicates an anomaly', 'goal': 'Optimize validation accuracy', 'initial_constraints': 'Use scikit-learn, or lSTM deep learning; preprocess data using time-windowing to capture temporal patterns'}`.\n",
      "   - Identify key characteristics such as number of samples, features, data types, missing values, correlations, or temporal patterns.\n",
      "   - Determine the task type (e.g., classification, regression, clustering) if specified, or infer it from the dataset and idea.\n",
      "\n",
      "2. **Understand the Research Idea**:\n",
      "   - Carefully analyze the idea: '{'dataset_info': {'size': '1440 rows x 3 columns', 'type': 'multivariate time-series', 'data_types': ['float64', 'float64', 'float64']}, 'missing_values': {'sensor_1': '0.97%', 'sensor_2': '0.97%', 'sensor_3': '0.97%', 'handling_method': 'linear interpolation', 'reason': 'Linear interpolation is chosen as it is generally superior for time-series data. It estimates missing values based on neighboring points, thus preserving the temporal continuity and trends inherent in sensor readings. This is crucial for maintaining the integrity of sequential data. Mean or median imputation, while simple, ignores temporal relationships and can introduce artificial flat segments or reduce variance, which is undesirable for time-series analysis and forecasting where the sequence and patterns are vital.'}, 'distribution': {'sensor_1': {'mean': 25.022516952668965, 'std': 7.067018673949446, 'min': 13.596933250579124, 'max': 36.06316898261613}, 'sensor_2': {'mean': 102.51875871436407, 'std': 2.0664506774380333, 'min': 97.82048135475868, 'max': 107.40018455423376}, 'sensor_3': {'mean': 59.96217539452159, 'std': 3.649102307502396, 'min': 52.79757406113937, 'max': 68.91551744385924}, 'notes': 'All sensors exhibit continuous numeric values. Sensor 1 (temperature-like) shows values mostly between 15-35, with a mean around 25, indicative of a typical daily temperature range. Sensor 2 (pressure-like) has a higher mean around 102-105 and a larger range, suggesting it captures more absolute variation. Sensor 3 (humidity-like) varies between 50-65, reflecting a daily humidity cycle. The standard deviations indicate the spread and variability of each sensor. No extreme outliers are apparent from the min/max values; distributions appear somewhat bell-shaped, likely influenced by the cyclical patterns.'}, 'correlation': {'matrix': [[1.0, 0.8199577077608203, 0.007950839655276333], [0.8199577077608203, 1.0, 0.013705505026781636], [0.007950839655276333, 0.013705505026781636, 1.0]], 'notes': 'Strong positive correlation (Pearson R=0.82) between Sensor 1 and Sensor 2.\\nWeak positive correlation (Pearson R=0.01) between Sensor 1 and Sensor 3.\\nWeak positive correlation (Pearson R=0.01) between Sensor 2 and Sensor 3.\\nImplications for tasks: High correlation between sensors can indicate redundancy. For example, if Sensor 1 and 2 are highly correlated, one might be sufficient for certain tasks, or their relationship can be used for anomaly detection (e.g., if one deviates while the other does not). It could also suggest an opportunity for dimensionality reduction (e.g., PCA). Low correlation suggests sensors capture independent aspects of the environment, providing a more comprehensive view when combined for tasks like anomaly detection or comprehensive system state monitoring. For forecasting, correlated sensors can serve as useful exogenous variables for each other.'}, 'trend_seasonality': {'trend': 'present (slight upward trend visible in Sensor 2, Sensor 1 and 3 are more cyclical)', 'seasonality': 'present (visually observed daily cycles for Sensor 1 and 3)', 'notes': 'Formal STL decomposition for a 24-hour (1440-minute) period could not be robustly performed due to the dataset only containing one full day of data. However, visual inspection of the time-series plots strongly suggests a daily (24-hour) cyclical pattern for Sensor 1 and Sensor 3, indicative of typical environmental changes (e.g., temperature/humidity cycles). Sensor 2 shows a slight upward trend over the day with some daily variations but less distinct seasonality.'}, 'preprocessing_recommendations': {'missing_values': 'linear interpolation (with fallback to mean/median for edge cases)', 'normalization': 'StandardScaler', 'time_windowing': '5-10 minute rolling windows (e.g., computing mean, std, min, max within each window)', 'reasons': \"**Missing Values Handling (Method: linear interpolation (with fallback to mean/median for edge cases))**:\\nLinear interpolation is highly recommended for time-series data because it preserves the temporal sequence and trends, estimating missing values based on their temporal neighbors. This is crucial for maintaining the integrity of patterns for tasks like forecasting or anomaly detection. In contrast, simple mean or median imputation can flatten data variance and distort temporal relationships, making it less suitable for time-series analysis.\\n\\n**Normalization (Method: StandardScaler)**:\\nStandardScaler is recommended as a versatile normalization method for sensor data. By transforming data to a mean of 0 and standard deviation of 1, it helps various machine learning algorithms (e.g., SVMs, neural networks, linear models) perform better, as they typically converge faster and are less biased when features are on a similar scale. It also helps preserve the relative magnitude of outliers, which can be critical for anomaly detection in sensor data. While MinMaxScaler is an alternative, StandardScaler often provides a more robust initial transformation for a wider array of tasks.\\n\\n**Time-Windowing (Method: 5-10 minute rolling windows (e.g., computing mean, std, min, max within each window))**:\\nTime-windowing is a vital preprocessing step for time-series sensor data. Aggregating data over short, fixed periods (e.g., 5-10 minutes) helps capture temporal patterns and dependencies that individual data points might miss. It effectively reduces noise, smooths rapid fluctuations, and generates new, informative features (e.g., the average value in the last 10 minutes, the standard deviation of readings, or the rate of change). These aggregated features are invaluable for tasks such as forecasting (predicting the next window's state), classification (identifying events based on a sequence of sensor states), and anomaly detection (recognizing unusual patterns over a short temporal context).\\n\\n**General Suitability for Tasks**:\\nThese preprocessing steps enhance the suitability of sensor data for diverse machine learning tasks. For **classification**, clean, normalized, and contextually rich windowed features enable models to learn distinct patterns associated with different operational states (e.g., normal vs. fault conditions). For **forecasting**, well-handled missing data, consistent scaling, and the creation of lagged or aggregated features provide the necessary temporal context and numerical stability for models to accurately predict future sensor readings. For **anomaly detection**, normalized data simplifies thresholding or model training for deviations from expected behavior, while time-windowing allows for the identification of anomalous *patterns* (e.g., unusual rate of change or sustained high variability) rather than just isolated point anomalies.\"}}' to understand the machine learning task and its objectives (e.g., what to predict or optimize).\n",
      "\n",
      "3. **Design the Pipeline**:\n",
      "   - **Model Selection**: Choose an appropriate model based on the task and dataset \n",
      "   - **Hyperparameters**: Select reasonable hyperparameters based on dataset size and complexity.\n",
      "   - **Preprocessing**: Specify preprocessing steps (e.g., impute missing values, scale features, encode categorical variables, feature engineering if needed).\n",
      "   - **Training**: Define the training process, including data splitting (e.g., 80% train, 10% validation, 10% test) and any validation techniques (e.g., cross-validation).\n",
      "   - **Evaluation Metrics**: Select multiple benchmarks suitable for the task (e.g., accuracy, precision, recall, F1-score for classification; MSE, RMSE for regression).\n",
      "\n",
      "4. **Generate the Prompt**:\n",
      "   - Create a prompt for the instruct LLM to write a Python script named `run_pipeline.py`.\n",
      "   - The prompt must include:\n",
      "     - **Task Overview**: Briefly describe the task and goal based on the idea.\n",
      "     - **Data Loading**: Specify how to load the dataset from its path (e.g., using pandas) and any specific parameters.\n",
      "     - **Preprocessing Steps**: List all preprocessing steps in sequence.\n",
      "     - **Model Configuration**: Define the model and its hyperparameters.\n",
      "     - **Training Process**: Explain how to train the model, including data splits and validation.\n",
      "     - **Evaluation**: Instruct to compute multiple evaluation metrics (e.g., accuracy, precision, recall, loss) on the test set.\n",
      "     - **Save Results**: Direct the LLM to:\n",
      "       - Create a \"result\" folder if it does not exist (e.g., using `os.makedirs`).\n",
      "       - Save a JSON file (e.g., `results.json`) in the \"result\" folder containing:\n",
      "         - All evaluation metrics computed on the test set.\n",
      "         - Hyperparameters used in the model.\n",
      "       - Ensure the script is modular and adaptable.\n",
      "\n",
      "### Additional Requirements:\n",
      "- The prompt must be detailed, specific to the dataset and idea, and follow a common structure for training AI models.\n",
      "- Do not include notes or comments in the generated source code.\n",
      "- Ensure the script uses multiple evaluation benchmarks as appropriate for the task.\n",
      "- The final script must save results in a \"result\" folder in a structured format (e.g., JSON).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "with open(\"idea.json\", \"r\", encoding='utf-8') as f:\n",
    "   idea_data = json.load(f)\n",
    "\n",
    "with open(\"analysis/results.json\", \"r\", encoding='utf-8') as f:\n",
    "    results_data = json.load(f)\n",
    "\n",
    "prompt_instruct = coding_instruct_prompt(idea_data, results_data)\n",
    "print(prompt_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4779a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = model.generate_content(prompt_instruct)\n",
    "prompt = responses.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e3df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Prompt for LLM to Generate Machine Learning Pipeline Script (`run_pipeline.py`)**\n",
      "\n",
      "**Objective:** Generate a robust Python script (`run_pipeline.py`) to train a supervised machine learning classifier for anomaly detection in multivariate time-series sensor data. The script should cover data generation (for demonstration), preprocessing (including missing value imputation, time-windowing feature engineering, and scaling), model training, evaluation, and structured result saving.\n",
      "\n",
      "**Dataset Information:**\n",
      "*   **Source:** For demonstration purposes, the script should *simulate* a multivariate time-series dataset.\n",
      "*   **Columns:** Three sensor readings: `sensor_1` (float), `sensor_2` (float), `sensor_3` (float).\n",
      "*   **Size:** The simulated dataset should consist of 1440 rows, representing 1-minute intervals over a 24-hour period.\n",
      "*   **Task:** Binary classification. The model needs to predict whether a given time window indicates an `is_anomaly` (binary: 0 for normal, 1 for anomaly).\n",
      "*   **Goal:** Optimize validation accuracy (though the script will focus on test set evaluation for simplicity).\n",
      "*   **Constraints:** The model should be a scikit-learn classifier.\n",
      "\n",
      "**Detailed Requirements for `run_pipeline.py`:**\n",
      "\n",
      "1.  **Imports:** Include all necessary libraries (e.g., `pandas`, `numpy`, `sklearn.preprocessing`, `sklearn.ensemble`, `sklearn.model_selection`, `sklearn.metrics`, `os`, `json`).\n",
      "\n",
      "2.  **Data Generation & Loading:**\n",
      "    *   Inside the script, create a synthetic pandas DataFrame named `df` with 1440 rows and three columns: `sensor_1`, `sensor_2`, `sensor_3`.\n",
      "    *   Populate these columns with simple time-series-like float values (e.g., sinusoidal patterns, random walks, or linear trends) to mimic sensor data.\n",
      "    *   Introduce approximately 1% missing values (`np.nan`) randomly across all sensor columns to simulate real-world data imperfections.\n",
      "\n",
      "3.  **Target Variable Simulation:**\n",
      "    *   Since a ground truth `is_anomaly` column is not provided, simulate this binary target variable (`y`) for demonstration.\n",
      "    *   A simple method could be to define an anomaly if `sensor_2` values deviate significantly (e.g., more than 2.5 standard deviations) from its mean, or if its rolling standard deviation within a window exceeds a certain threshold. Alternatively, randomly assign a small percentage (e.g., 5-10%) of the time windows as `1` (anomaly) and the rest as `0` (normal). *Prioritize a method that uses time-window statistics for a more realistic simulation.*\n",
      "\n",
      "4.  **Preprocessing Steps:**\n",
      "    *   **Missing Value Imputation:** Apply `df.interpolate(method='linear')` to fill the missing values (`NaN`) in `sensor_1`, `sensor_2`, and `sensor_3`.\n",
      "    *   **Time-Windowing Feature Engineering:**\n",
      "        *   Apply a rolling window of **10 minutes** (10 rows) to `sensor_1`, `sensor_2`, and `sensor_3`.\n",
      "        *   For each window, calculate the following statistical features: `mean`, `standard deviation`, `minimum`, and `maximum`.\n",
      "        *   Concatenate these features (which will total 12 features: 4 stats * 3 sensors) to form the new feature set `X`.\n",
      "        *   Align the target `y` (the simulated `is_anomaly` column) with the *end* of each rolling window. Ensure that any rows introduced by padding (NaNs from rolling window) are dropped from both `X` and `y` to maintain alignment and remove incomplete windows.\n",
      "    *   **Feature Scaling:** Apply `StandardScaler` to the engineered features `X`.\n",
      "\n",
      "5.  **Data Splitting:**\n",
      "    *   Split the preprocessed features `X` and target `y` into training, validation, and test sets.\n",
      "    *   Maintain temporal order by performing a sequential split:\n",
      "        *   **80%** of the data for the **training set**.\n",
      "        *   **10%** for the **validation set**.\n",
      "        *   **10%** for the **test set**.\n",
      "    *   Store these as `X_train`, `y_train`, `X_val`, `y_val`, `X_test`, `y_test`.\n",
      "\n",
      "6.  **Model Selection and Training:**\n",
      "    *   **Model:** Utilize `sklearn.ensemble.RandomForestClassifier`.\n",
      "    *   **Hyperparameters:** Initialize with reasonable default or common hyperparameters (e.g., `n_estimators=100`, `random_state=42`). Store these parameters in a dictionary.\n",
      "    *   Train the `RandomForestClassifier` model using `X_train` and `y_train`.\n",
      "\n",
      "7.  **Evaluation:**\n",
      "    *   Make predictions on the **test set** (`X_test`).\n",
      "    *   Calculate and print the following evaluation metrics for the test set:\n",
      "        *   `Accuracy`\n",
      "        *   `Precision` (use `average='weighted'` to account for class imbalance if present)\n",
      "        *   `Recall` (use `average='weighted'`)\n",
      "        *   `F1-Score` (use `average='weighted'`)\n",
      "\n",
      "8.  **Save Results:**\n",
      "    *   Create a directory named `result` in the current working directory if it does not already exist.\n",
      "    *   Save a JSON file named `results.json` inside the `result` directory.\n",
      "    *   The `results.json` file should contain:\n",
      "        *   All computed evaluation metrics (accuracy, precision, recall, f1-score).\n",
      "        *   The hyperparameters used for the `RandomForestClassifier` model.\n",
      "\n",
      "**Code Structure and Modularity:**\n",
      "*   The script should be executable directly from the command line.\n",
      "*   Use clear, descriptive variable names.\n",
      "*   Ensure the code is clean and follows standard Python practices.\n",
      "*   Do not include extraneous comments in the generated Python code.\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7017c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "responsess = model.generate_content(prompt)\n",
    "prompts = responsess.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939202ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
      "import os\n",
      "import json\n",
      "\n",
      "# --- Configuration ---\n",
      "N_ROWS = 1440  # 24 hours * 60 minutes\n",
      "MISSING_VALUE_RATE = 0.01\n",
      "ROLLING_WINDOW_SIZE = 10  # 10 minutes\n",
      "TEST_SPLIT_RATIO = 0.10\n",
      "VAL_SPLIT_RATIO = 0.10\n",
      "RANDOM_STATE = 42\n",
      "\n",
      "# Define output directory and file\n",
      "OUTPUT_DIR = 'result'\n",
      "RESULTS_FILE = os.path.join(OUTPUT_DIR, 'results.json')\n",
      "\n",
      "# --- Data Generation ---\n",
      "print(\"1. Generating synthetic multivariate time-series data...\")\n",
      "# Generate time index for a 24-hour period (1-minute intervals)\n",
      "time_index = pd.date_range(start='2023-01-01', periods=N_ROWS, freq='min')\n",
      "\n",
      "# Simulate sensor data with some patterns\n",
      "np.random.seed(RANDOM_STATE)\n",
      "df = pd.DataFrame(index=time_index)\n",
      "df['sensor_1'] = 10 * np.sin(np.linspace(0, 4 * np.pi, N_ROWS)) + np.random.normal(0, 0.5, N_ROWS)\n",
      "df['sensor_2'] = 20 + 5 * np.cos(np.linspace(0, 2 * np.pi, N_ROWS)) + np.random.normal(0, 1, N_ROWS)\n",
      "df['sensor_3'] = 50 + np.linspace(0, 10, N_ROWS) + np.random.normal(0, 0.8, N_ROWS)\n",
      "\n",
      "# Introduce approximately 1% missing values\n",
      "for col in ['sensor_1', 'sensor_2', 'sensor_3']:\n",
      "    df.loc[df.sample(frac=MISSING_VALUE_RATE, random_state=RANDOM_STATE).index, col] = np.nan\n",
      "\n",
      "# Simulate anomaly target variable\n",
      "# Define a few specific time windows where anomalies occur\n",
      "df['is_anomaly'] = 0\n",
      "# Anomaly 1: Spike in sensor_2\n",
      "df.loc[df.index[200:210], 'sensor_2'] += 15\n",
      "df.loc[df.index[200:210], 'is_anomaly'] = 1\n",
      "# Anomaly 2: Dip in sensor_1\n",
      "df.loc[df.index[500:510], 'sensor_1'] -= 10\n",
      "df.loc[df.index[500:510], 'is_anomaly'] = 1\n",
      "# Anomaly 3: General unusual pattern across sensors\n",
      "df.loc[df.index[800:810], 'sensor_1'] += 8\n",
      "df.loc[df.index[800:810], 'sensor_2'] += 8\n",
      "df.loc[df.index[800:810], 'sensor_3'] -= 8\n",
      "df.loc[df.index[800:810], 'is_anomaly'] = 1\n",
      "\n",
      "print(f\"Generated DataFrame shape: {df.shape}\")\n",
      "print(f\"Initial missing values:\\n{df.isnull().sum()}\")\n",
      "print(f\"Initial anomaly distribution:\\n{df['is_anomaly'].value_counts()}\")\n",
      "\n",
      "# --- Preprocessing Steps ---\n",
      "print(\"\\n2. Preprocessing data...\")\n",
      "\n",
      "# Missing Value Imputation\n",
      "print(\"  - Imputing missing values using linear interpolation...\")\n",
      "df_imputed = df.copy()\n",
      "for col in ['sensor_1', 'sensor_2', 'sensor_3']:\n",
      "    df_imputed[col] = df_imputed[col].interpolate(method='linear', limit_direction='both', axis=0)\n",
      "print(f\"Missing values after imputation:\\n{df_imputed.isnull().sum()}\")\n",
      "\n",
      "# Time-Windowing Feature Engineering\n",
      "print(f\"  - Applying {ROLLING_WINDOW_SIZE}-minute rolling window feature engineering...\")\n",
      "X_features = []\n",
      "for sensor_col in ['sensor_1', 'sensor_2', 'sensor_3']:\n",
      "    rolling_data = df_imputed[sensor_col].rolling(window=ROLLING_WINDOW_SIZE)\n",
      "    X_features.append(rolling_data.mean().rename(f'{sensor_col}_mean'))\n",
      "    X_features.append(rolling_data.std().rename(f'{sensor_col}_std'))\n",
      "    X_features.append(rolling_data.min().rename(f'{sensor_col}_min'))\n",
      "    X_features.append(rolling_data.max().rename(f'{sensor_col}_max'))\n",
      "\n",
      "X = pd.concat(X_features, axis=1)\n",
      "\n",
      "# Align target 'y' with the end of each rolling window and drop NaNs\n",
      "# The rolling window operation creates NaNs for the first (ROLLING_WINDOW_SIZE - 1) rows.\n",
      "# These rows must be dropped from both X and y.\n",
      "y = df_imputed['is_anomaly'].iloc[ROLLING_WINDOW_SIZE - 1:].copy()\n",
      "X = X.iloc[ROLLING_WINDOW_SIZE - 1:].copy()\n",
      "\n",
      "# Ensure X and y have the same number of rows and indices match\n",
      "# In case any NaNs remain from rolling operations (e.g., if a window was entirely NaN initially)\n",
      "# Note: Linear interpolation before rolling should prevent this for our synthetic data.\n",
      "valid_indices = X.dropna().index\n",
      "X = X.loc[valid_indices]\n",
      "y = y.loc[valid_indices]\n",
      "\n",
      "print(f\"Features (X) shape after windowing: {X.shape}\")\n",
      "print(f\"Target (y) shape after alignment: {y.shape}\")\n",
      "print(f\"Anomaly distribution after windowing and alignment:\\n{y.value_counts()}\")\n",
      "\n",
      "# Feature Scaling\n",
      "print(\"  - Scaling features using StandardScaler...\")\n",
      "scaler = StandardScaler()\n",
      "X_scaled = scaler.fit_transform(X)\n",
      "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index) # Convert back to DataFrame\n",
      "\n",
      "# --- Data Splitting ---\n",
      "print(\"\\n3. Splitting data into training, validation, and test sets (sequential split)...\")\n",
      "n_samples = len(X_scaled)\n",
      "train_end_idx = int(n_samples * (1 - TEST_SPLIT_RATIO - VAL_SPLIT_RATIO))\n",
      "val_end_idx = int(n_samples * (1 - TEST_SPLIT_RATIO))\n",
      "\n",
      "X_train, y_train = X_scaled.iloc[:train_end_idx], y.iloc[:train_end_idx]\n",
      "X_val, y_val = X_scaled.iloc[train_end_idx:val_end_idx], y.iloc[train_end_idx:val_end_idx]\n",
      "X_test, y_test = X_scaled.iloc[val_end_idx:], y.iloc[val_end_idx:]\n",
      "\n",
      "print(f\"Train set shape: X={X_train.shape}, y={y_train.shape}\")\n",
      "print(f\"Validation set shape: X={X_val.shape}, y={y_val.shape}\")\n",
      "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
      "\n",
      "# --- Model Selection and Training ---\n",
      "print(\"\\n4. Training RandomForestClassifier model...\")\n",
      "model_params = {\n",
      "    'n_estimators': 100,\n",
      "    'random_state': RANDOM_STATE,\n",
      "    'class_weight': 'balanced' # Useful for imbalanced anomaly detection problems\n",
      "}\n",
      "model = RandomForestClassifier(**model_params)\n",
      "model.fit(X_train, y_train)\n",
      "print(\"Model training complete.\")\n",
      "\n",
      "# --- Evaluation ---\n",
      "print(\"\\n5. Evaluating model on the test set...\")\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
      "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
      "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
      "\n",
      "print(f\"  Accuracy: {accuracy:.4f}\")\n",
      "print(f\"  Precision (weighted): {precision:.4f}\")\n",
      "print(f\"  Recall (weighted): {recall:.4f}\")\n",
      "print(f\"  F1-Score (weighted): {f1:.4f}\")\n",
      "\n",
      "# --- Save Results ---\n",
      "print(f\"\\n6. Saving results to {RESULTS_FILE}...\")\n",
      "results_to_save = {\n",
      "    'model_name': 'RandomForestClassifier',\n",
      "    'hyperparameters': model_params,\n",
      "    'test_metrics': {\n",
      "        'accuracy': accuracy,\n",
      "        'precision_weighted': precision,\n",
      "        'recall_weighted': recall,\n",
      "        'f1_score_weighted': f1\n",
      "    },\n",
      "    'data_pipeline_summary': {\n",
      "        'n_rows_original': N_ROWS,\n",
      "        'missing_value_rate': MISSING_VALUE_RATE,\n",
      "        'rolling_window_size': ROLLING_WINDOW_SIZE,\n",
      "        'train_split_ratio': 1 - TEST_SPLIT_RATIO - VAL_SPLIT_RATIO,\n",
      "        'validation_split_ratio': VAL_SPLIT_RATIO,\n",
      "        'test_split_ratio': TEST_SPLIT_RATIO,\n",
      "        'num_features_engineered': X.shape[1],\n",
      "        'total_samples_after_windowing': X.shape[0]\n",
      "    }\n",
      "}\n",
      "\n",
      "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
      "with open(RESULTS_FILE, 'w') as f:\n",
      "    json.dump(results_to_save, f, indent=4)\n",
      "\n",
      "print(\"Pipeline execution complete. Results saved.\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e066a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Code written to run_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "match = re.search(r\"```(?:python)?\\s*(.*?)```\", prompts, re.DOTALL)\n",
    "code = match.group(1).strip() if match else prompts.strip()\n",
    "\n",
    "# 5. Ghi code ra file\n",
    "with open(\"run_pipeline.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "print(\"✅ Code written to run_pipeline.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75918d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
